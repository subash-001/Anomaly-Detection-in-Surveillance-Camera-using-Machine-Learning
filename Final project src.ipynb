{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2799594,"sourceType":"datasetVersion","datasetId":1710176},{"sourceId":7066541,"sourceType":"datasetVersion","datasetId":4069026},{"sourceId":7553728,"sourceType":"datasetVersion","datasetId":4399484},{"sourceId":7554122,"sourceType":"datasetVersion","datasetId":4399695},{"sourceId":7570663,"sourceType":"datasetVersion","datasetId":4407360},{"sourceId":7570728,"sourceType":"datasetVersion","datasetId":4407395},{"sourceId":7570752,"sourceType":"datasetVersion","datasetId":4407407},{"sourceId":7578231,"sourceType":"datasetVersion","datasetId":4411634},{"sourceId":7579384,"sourceType":"datasetVersion","datasetId":4412092},{"sourceId":7613066,"sourceType":"datasetVersion","datasetId":4433352},{"sourceId":7613143,"sourceType":"datasetVersion","datasetId":4433396},{"sourceId":7613254,"sourceType":"datasetVersion","datasetId":4371594},{"sourceId":7613290,"sourceType":"datasetVersion","datasetId":4433498},{"sourceId":7616366,"sourceType":"datasetVersion","datasetId":4433145},{"sourceId":7698313,"sourceType":"datasetVersion","datasetId":4493190},{"sourceId":7702265,"sourceType":"datasetVersion","datasetId":4407342},{"sourceId":7710701,"sourceType":"datasetVersion","datasetId":4502366},{"sourceId":8467,"sourceType":"modelInstanceVersion","modelInstanceId":6691}],"dockerImageVersionId":30474,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Anomaly Detection in Surveillance videos</center>\n","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing\n\nExtracting out the category labels","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nimport os\nimport cv2\nimport pickle\nfrom tqdm import tqdm\nimport numpy as np\nimport random\n\ntest_dir = '/kaggle/input/crimedataset/Test/Test'\ntrain_dir = '/kaggle/input/crimedataset/Train/Train'\n\n# Define the categories and labels\ncategories_labels = {\n    'Fighting': 0, \n    'Shoplifting': 1, \n    'Abuse': 2, \n    'Arrest': 3, \n    'Shooting': 4, \n    'Robbery': 5, \n    'Explosion': 6,\n    'RoadAccidents':7\n}\n\n\n\ndef load_data(base_dir, categories_labels):\n    data = []\n    \n    # Go through each category\n    for category, label in categories_labels.items():\n        # The path to the category directory\n        category_dir = os.path.join(base_dir, category)\n\n        # Make sure the directory exists\n        if os.path.isdir(category_dir):\n            # Go through each file in the directory\n            for filename in tqdm(os.listdir(category_dir), desc=f\"Loading {category}\"):\n                # Make sure the file is an image\n                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n                    # The path to the image\n                    image_path = os.path.join(category_dir, filename)\n\n                    try:\n                        # Load the image\n                        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n                        # Resize the image\n                        image = cv2.resize(image, (50, 50))\n\n                        # Reshape the image to 4D array \n                        #(ImageDataGenerator requires 4D array)\n                        image = image.reshape((1,) + image.shape + (1,))\n\n                        # Add the image and its label to the data\n                        data.append([image, label])\n                    except Exception as e:\n                        print(f\"Error loading image {image_path}: {e}\")\n\n    return data\n\n# Load the training and test data\ntraining_data = load_data(train_dir, categories_labels)\ntest_data = load_data(test_dir, categories_labels)\n\n# Combine the training and test data\ntotal_data = training_data + test_data\n\nprint(f\"Loaded {len(total_data)} images.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:14.379488Z","iopub.execute_input":"2024-02-26T03:57:14.380893Z","iopub.status.idle":"2024-02-26T03:57:39.251220Z","shell.execute_reply.started":"2024-02-26T03:57:14.380813Z","shell.execute_reply":"2024-02-26T03:57:39.249884Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Loading Fighting: 100%|██████████| 2000/2000 [00:04<00:00, 473.35it/s]\nLoading Shooting: 100%|██████████| 1821/1821 [00:04<00:00, 452.79it/s]\nLoading RoadAccidents: 100%|██████████| 1857/1857 [00:04<00:00, 464.05it/s]\nLoading Fighting: 100%|██████████| 2000/2000 [00:04<00:00, 463.51it/s]\nLoading Shooting: 100%|██████████| 1821/1821 [00:04<00:00, 451.38it/s]\nLoading RoadAccidents: 100%|██████████| 1857/1857 [00:04<00:00, 441.22it/s]","output_type":"stream"},{"name":"stdout","text":"Loaded 11356 images.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(training_data))\nprint(len(test_data))\nprint(len(total_data))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:39.253763Z","iopub.execute_input":"2024-02-26T03:57:39.254569Z","iopub.status.idle":"2024-02-26T03:57:39.261448Z","shell.execute_reply.started":"2024-02-26T03:57:39.254525Z","shell.execute_reply":"2024-02-26T03:57:39.260291Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"5678\n5678\n11356\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\nfrom keras.layers import LSTM, TimeDistributed, Conv1D, MaxPooling1D\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import concatenate\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nimport time\n\n\n# Initialize lists to store the images and the labels\nimages = []\nlabels = []\n\n# Go through each image and its label in the total_data\nfor image, label in total_data:\n    images.append(image)\n    labels.append(label)\n\n# Convert the lists into numpy arrays\nimages = np.array(images)\nlabels = np.array(labels)\nprint(images.shape)\n\n# Reshape images for LSTM\nimages_lstm = images.reshape(images.shape[0], -1, 1)  # Added third dimension for features\n\n# Set a seed for reproducibility\nseed = 51 #9 + 14 + 28\n\n# Split the data into training and testing sets for CNN\ntrain_images_cnn, test_images_cnn, train_labels_cnn, test_labels_cnn = train_test_split(images, labels, test_size=0.1, random_state=seed)\n\n# Split the data into training and testing sets for LSTM\ntrain_images_lstm, test_images_lstm, train_labels_lstm, test_labels_lstm = train_test_split(images_lstm, labels, test_size=0.1, random_state=seed)\n\n# Convert labels to categorical for CNN\ntrain_labels_cnn = np_utils.to_categorical(train_labels_cnn, len(categories_labels))\ntest_labels_cnn = np_utils.to_categorical(test_labels_cnn, len(categories_labels))\n\n# Convert labels to categorical for LSTM\ntrain_labels_lstm = np_utils.to_categorical(train_labels_lstm, len(categories_labels))\ntest_labels_lstm = np_utils.to_categorical(test_labels_lstm, len(categories_labels))\n\n# Remove the second dimension from your data\ntrain_images_cnn = np.squeeze(train_images_cnn, axis=1)\ntest_images_cnn = np.squeeze(test_images_cnn, axis=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:39.262990Z","iopub.execute_input":"2024-02-26T03:57:39.263643Z","iopub.status.idle":"2024-02-26T03:57:39.335657Z","shell.execute_reply.started":"2024-02-26T03:57:39.263600Z","shell.execute_reply":"2024-02-26T03:57:39.334410Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(11356, 1, 50, 50, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Custom Model - CNN & LSTM","metadata":{}},{"cell_type":"code","source":"model_CNN = Sequential()\nmodel_CNN.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=(50, 50, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D((2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(128, (3, 3), padding='same')) \nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(256, (3, 3), padding='same'))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.4))  \nmodel_CNN.add(Flatten()) \nmodel_CNN.add(Dense(256)) \nmodel_CNN.add(LeakyReLU(alpha=0.1))            \nmodel_CNN.add(Dropout(0.5)) \n\n# LSTM Model\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(units = 8, return_sequences = True, input_shape = (2500, 1), activation='tanh'))\nmodel_lstm.add(LSTM(units = 8, return_sequences = True))\nmodel_lstm.add(Dense(4, activation='tanh'))\nmodel_lstm.add(Dropout(0.2))\nmodel_lstm.add(Flatten())\n\n# Combine CNN and LSTM model\nnb_classes = 7\ncombined = concatenate([model_CNN.output, model_lstm.output], axis=-1)\noutput = Dense(nb_classes, activation='softmax')(combined)\nmodel_final = Model(inputs=[model_CNN.input, model_lstm.input], outputs=output)\n\n# Plot and compile the model\nplot_model(model_final, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n\nmodel_final.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Callbacks\ncsv_logger = CSVLogger('training.log', separator=',', append=False)\nmc = ModelCheckpoint('CNN_LSTM.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\n# Training\ntime1 = time.time()\nhistory = model_final.fit([train_images_cnn, train_images_lstm], train_labels_lstm, batch_size=1000, epochs=20, validation_data=([test_images_cnn, test_images_lstm], test_labels_lstm), callbacks=[mc, csv_logger])\nprint ((\"Training time=\", time.time()-time1))\n\n# Save training history\nnp.save(\"CNN_LSTM_history.npy\", history.history)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:39.338928Z","iopub.execute_input":"2024-02-26T03:57:39.339589Z","iopub.status.idle":"2024-02-26T03:57:40.321590Z","shell.execute_reply.started":"2024-02-26T03:57:39.339554Z","shell.execute_reply":"2024-02-26T03:57:40.320323Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<!-- #CNN Model\nmodel_CNN = Sequential()\nmodel_CNN.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=(50, 50, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D((2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(128, (3, 3), padding='same')) \nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(256, (3, 3), padding='same'))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.4))  \nmodel_CNN.add(Flatten()) \nmodel_CNN.add(Dense(256)) \nmodel_CNN.add(LeakyReLU(alpha=0.1))            \nmodel_CNN.add(Dropout(0.5)) \n\n# LSTM Model\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(units = 8, return_sequences = True, input_shape = (2500, 1), activation='tanh'))\nmodel_lstm.add(LSTM(units = 8, return_sequences = True))\nmodel_lstm.add(Dense(4, activation='tanh'))\nmodel_lstm.add(Dropout(0.2))\nmodel_lstm.add(Flatten())\n\n# Combine CNN and LSTM model\n#nb_classes = len(class_names)\nnb = 7\ncombined = concatenate([model_CNN.output, model_lstm.output], axis=-1)\noutput = Dense(nb, activation='softmax')(combined)\nmodel_final = Model(inputs=[model_CNN.input, model_lstm.input], outputs=output)\n\n# Plot and compile the model\nplot_model(model_final, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n\nmodel_final.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Callbacks\ncsv_logger = CSVLogger('training.log', separator=',', append=False)\nmc = ModelCheckpoint('CNN_LSTM.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\n# Training\ntime1 = time.time()\nhistory = model_final.fit([train_images_cnn, train_images_lstm], \n                          train_labels_lstm,\n                          batch_size=1000,\n                          epochs=1, \n                          validation_data=([test_images_cnn, test_images_lstm],\n                                           test_labels_lstm), \n                          callbacks=[mc, csv_logger])\nprint ((\"Training time=\", time.time()-time1))\n\n# Save training history\nnp.save(\"CNN_LSTM_history.npy\", history.history)\n -->","metadata":{"execution":{"iopub.status.busy":"2024-02-05T08:39:31.893944Z","iopub.execute_input":"2024-02-05T08:39:31.894309Z","iopub.status.idle":"2024-02-05T08:42:07.616107Z","shell.execute_reply.started":"2024-02-05T08:39:31.894281Z","shell.execute_reply":"2024-02-05T08:42:07.615102Z"}}},{"cell_type":"markdown","source":"# Model Analytics\n","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nfashion_model = load_model('./CNN_LSTM.h5') # load model\nfashion_model.summary() # summarize model.\n\nfrom contextlib import redirect_stdout\nwith open('./CNN_LSTM'+\".xls\", 'w') as f:\n    with redirect_stdout(f):\n        fashion_model.summary()\n        \nval_loss, val_accuracy=fashion_model.evaluate([test_images_cnn, test_images_lstm] ,test_labels_cnn) ## to get test accuracy and losses\nprint(val_loss, val_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.323175Z","iopub.execute_input":"2024-02-26T03:57:40.323626Z","iopub.status.idle":"2024-02-26T03:57:40.409982Z","shell.execute_reply.started":"2024-02-26T03:57:40.323583Z","shell.execute_reply":"2024-02-26T03:57:40.407534Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m----> 2\u001b[0m fashion_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./CNN_LSTM.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fashion_model\u001b[38;5;241m.\u001b[39msummary() \u001b[38;5;66;03m# summarize model.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m redirect_stdout\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/saving/legacy/save.py:227\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    233\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    234\u001b[0m         )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at ./CNN_LSTM.h5"],"ename":"OSError","evalue":"No file or directory found at ./CNN_LSTM.h5","output_type":"error"}]},{"cell_type":"code","source":"time2=time.time()\npredict_prob=fashion_model.predict([test_images_cnn, test_images_lstm])\ny_pred=np.argmax(predict_prob,axis=1)\nprint ('classification time:', time.time()-time2)\n\n##print (y_pred)\ny_true=np.argmax(test_labels_cnn, axis=1)\nfrom sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_true, y_pred)\nprint (cm)\nprint(classification_report(y_true, y_pred))\n\nprecision = precision_score(y_true, y_pred, average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_true, y_pred, average='weighted')\nprint('Recall: %f' % recall)\n# f1: tp / (tp + fp + fn)\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint('F1 score: %f' % f1)\n#-----------  IoU\nfrom sklearn.metrics import jaccard_score\nprint ('IoU:', jaccard_score(y_true, y_pred, average='micro'))\n\n\ntest_eval = fashion_model.evaluate([test_images_cnn, test_images_lstm], test_labels_cnn)\n\nloss, accuracy = fashion_model.evaluate([train_images_cnn, train_images_lstm], train_labels_cnn)\nprint('loss_train: ', loss, 'accuracy_train: ', accuracy)\nprint('Test loss:', test_eval[0], 'Test accuracy:', test_eval[1])","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.411276Z","iopub.status.idle":"2024-02-26T03:57:40.411697Z","shell.execute_reply.started":"2024-02-26T03:57:40.411499Z","shell.execute_reply":"2024-02-26T03:57:40.411518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistory_dict=history.history\nloss_values=history_dict['loss']\nval_loss_values=history_dict['val_loss']\nacc_values=history_dict['accuracy']\nval_acc_values=history_dict['val_accuracy']\nepochs=range(1, len(acc_values)+1)\ndef smooth_curve(points, factor=0.8):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\nloss_values=smooth_curve(loss_values)\nval_loss_values=smooth_curve(val_loss_values)\nacc_values=smooth_curve(acc_values)\nval_acc_values=smooth_curve(val_acc_values)\n\nfont = {'family' : 'serif',\n        'color'  : 'black',\n        'weight' : 'normal',\n        'size'   : 12}\n        \n\nplt.plot(epochs, acc_values, 'r-', label='Training acc')\nplt.plot(epochs, val_acc_values, 'g', label='Validation acc')\nplt.title('Training and Validation acc', fontdict=font)\nplt.xlabel('Epochs', fontdict=font)\nplt.ylabel('Accuracy', fontdict=font)\nplt.legend()\nplt.savefig(\"accuracy\"+'CNN_LSTM'+\".png\")\nplt.show()\n\nplt.plot(epochs, loss_values, 'b-', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and Validation loss', fontdict=font)\nplt.xlabel('Epochs',fontdict=font)\nplt.ylabel('Loss',fontdict=font)\nplt.legend()\nplt.savefig(\"loss\"+'CNN_LSTM'+\".png\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.413638Z","iopub.status.idle":"2024-02-26T03:57:40.414296Z","shell.execute_reply.started":"2024-02-26T03:57:40.414089Z","shell.execute_reply":"2024-02-26T03:57:40.414111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Fighting', 'Shoplifting', 'Abuse', 'Arrest', 'Shooting', 'Robbery', 'Explosion','RoadAccidents']\n# train_dir = '/kaggle/input/ucf-crime-dataset/Train'\n# class_names = os.listdir(train_dir)\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\nfont = {'family' : 'serif',\n        'color'  : 'black',\n        'weight' : 'normal',\n        'size'   : 14}\n\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(y_true, y_pred, classes=class_names,\n                      title='Confusion matrix, without normalization')\nplt.savefig('confusion matrix1'+'CNN_LSTM'+'.png')\nplt.show()\n# Plot normalized confusion matrix\nplot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\nplt.savefig('confusion matrix2'+'CNN_LSTM'+'.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.415413Z","iopub.status.idle":"2024-02-26T03:57:40.415993Z","shell.execute_reply.started":"2024-02-26T03:57:40.415789Z","shell.execute_reply":"2024-02-26T03:57:40.415809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing with Input Image","metadata":{}},{"cell_type":"code","source":"# import cv2\n# import numpy as np\n# from keras.models import load_model\n\n# categories_labels = {'Fighting': 0, 'Shoplifting': 1, 'Abuse': 2, 'Arrest': 3, 'Shooting': 4, 'Robbery': 5, 'Explosion': 6}\n# labels_categories = {v: k for k, v in categories_labels.items()}  # reverse dictionary for label lookup\n\n# # Load the trained model\n# model = load_model('/kaggle/input/cnn_lstm/keras/cnn_lstm/1/CNN_LSTM.h5')\n\n# def predict_image(image_path):\n#     # Load the image\n#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n#     # Resize the image\n#     image = cv2.resize(image, (50, 50))\n\n#     # Reshape the image to 4D array for CNN and LSTM input\n#     image_cnn = image.reshape((1,) + image.shape + (1,))\n#     image_lstm = image.reshape((1,) + (-1, 1))\n\n#     # Use the model to predict the category of the image\n#     prediction = model.predict([image_cnn, image_lstm])\n    \n#     # Find the category with the highest probability\n#     label = np.argmax(prediction)\n\n#     # Return the name of the category\n#     return labels_categories[label]\n\n# # Test the function\n# image_path1 = \"/kaggle/input/test-image/75089289-12483959-Kirk_Wharton_is_seen_on_CCTV_stashing_item_in_his_coat_in_a_foil-a-45_1693940026231.jpg\"  # Replace with your image path\n# img_path2=\"/kaggle/input/normal/Albisola-Marina-Italy.jpeg\";\n# i1=\"/kaggle/input/fighting/fight.jpg\";\n# i2=\"/kaggle/input/explosion/rawImage.jpg\";\n# i3=\"/kaggle/input/fight/fighting-1200x801.jpg\";\n# i4=\"/kaggle/input/robbery/r10_0_709_394_w1200_h678_fmax.jpg\";\n# i5=\"/kaggle/input/fight-5/cory-booker.jpg\";\n# #print(predict_image(image_path1));\n# # print(predict_image(i2));\n# print(predict_image(i3));\n# # print(\"rob\",predict_image(i4));\n# # print(predict_image(i5));\n# #print(predict_image(img_path2))\n\n# def extract_and_predict(video_path):\n#     # Open the video\n#     cap = cv2.VideoCapture(video_path)\n\n#     # Create a new directory to save predicted images\n#     new_dir = 'predicted_images'\n#     os.makedirs(new_dir, exist_ok=True)\n\n#     # Initialize variables\n#     frame_count = 0\n#     last_category = None\n\n#     # Loop through the frames\n#     while cap.isOpened():\n#         ret, frame = cap.read()\n#         if not ret:\n#             break\n\n#         # Convert the frame to grayscale\n#         frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n#         # Predict the category of the frame\n#         category = predict_image(frame_gray)\n\n#         # Print the category if it's different from the last one\n#         if category != last_category:\n#             print('Frame', frame_count, 'Category:', category)\n#         last_category = category\n\n#         # Save the frame with the predicted category\n#         cv2.imwrite(os.path.join(new_dir, f'{category}_{frame_count}.png'), frame_gray)\n\n#         frame_count += 1\n\n#     cap.release()\n#     cv2.destroyAllWindows()\n\n# # Test the function\n# # video_path = \"/kaggle/input/new-video/sample.mp4\"  # Replace with your video path\n# # extract_and_predict(video_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.417048Z","iopub.status.idle":"2024-02-26T03:57:40.417633Z","shell.execute_reply.started":"2024-02-26T03:57:40.417435Z","shell.execute_reply":"2024-02-26T03:57:40.417454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import smtplib\n# from email.mime.multipart import MIMEMultipart\n# from email.mime.text import MIMEText\n# from email.mime.image import MIMEImage\n# import getpass\n\n# HOST = 'smtp-mail.outlook.com'\n# PORT = 587\n\n# FROM_EMAIL = \"anomalytest@outlook.com\"\n# TO_EMAIL = \"subashscr7@gmail.com\"\n# PASSWORD = \"project24\"\n\n# predicted_category = predict_image(i2)\n# MESSAGE = MIMEMultipart()\n# MESSAGE['Subject'] = \"Predicted Category\"\n# MESSAGE['From'] = FROM_EMAIL\n# MESSAGE['To'] = TO_EMAIL\n\n# # Attach predicted category as text\n# text = MIMEText(f'The predicted category of the image is: {predicted_category}')\n# MESSAGE.attach(text)\n\n# # Attach image\n# with open('/kaggle/input/robbery/r10_0_709_394_w1200_h678_fmax.jpg', 'rb') as img_file:\n#     img = MIMEImage(img_file.read())\n#     img.add_header('Content-Disposition', 'attachment', filename=\"r10_0_709_394_w1200_h678_fmax.jpg\")\n#     MESSAGE.attach(img)\n\n# smtp = smtplib.SMTP(HOST, PORT)\n# smtp.starttls()\n# smtp.login(FROM_EMAIL, PASSWORD)\n\n# smtp.sendmail(FROM_EMAIL, TO_EMAIL, MESSAGE.as_string())\n# smtp.quit()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.418772Z","iopub.status.idle":"2024-02-26T03:57:40.419183Z","shell.execute_reply.started":"2024-02-26T03:57:40.418979Z","shell.execute_reply":"2024-02-26T03:57:40.418997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST WITH RECORDED VIDEO","metadata":{}},{"cell_type":"code","source":"# import cv2\n# import numpy as np\n# import os  # Import the os module\n# from keras.models import load_model\n\n# # Define the labels and categories\n# categories_labels = {'Fighting': 0, 'Shoplifting': 1, 'Abuse': 2, 'Arrest': 3, 'Shooting': 4, 'Robbery': 5, 'Explosion': 6}\n# labels_categories = {v: k for k, v in categories_labels.items()}  # reverse dictionary for label lookup\n\n# # Load the trained model\n# model = load_model('/kaggle/input/cnn_lstm/keras/cnn_lstm/1/CNN_LSTM.h5')\n\n# def predict_image(image):\n#     # Resize the image\n#     image = cv2.resize(image, (50, 50))\n\n#     # Reshape the image to 4D array for CNN and LSTM input\n#     image_cnn = image.reshape((1,) + image.shape + (1,))\n#     image_lstm = image.reshape((1,) + (-1, 1))\n\n#     # Use the model to predict the category of the image\n#     prediction = model.predict([image_cnn, image_lstm])\n\n#     # Find the category with the highest probability\n#     label = np.argmax(prediction)\n\n#     # Return the name of the category\n#     return labels_categories[label]\n\n# def extract_and_predict(video_path):\n#     # Open the video\n#     cap = cv2.VideoCapture(video_path)\n\n#     # Create a new directory to save predicted images\n#     new_dir = 'predicted_images'\n#     os.makedirs(new_dir, exist_ok=True)\n\n#     # Initialize variables\n#     frame_count = 0\n#     last_category = None\n\n#     # Loop through the frames\n#     while cap.isOpened():\n#         ret, frame = cap.read()\n#         if not ret:\n#             break\n\n#         # Convert the frame to grayscale\n#         frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n#         # Predict the category of the frame\n#         category = predict_image(frame_gray)\n\n#         # Print the category if it's different from the last one\n#         if category != last_category:\n#             print('Frame', frame_count, 'Category:', category)\n#         last_category = category\n\n#         # Save the frame with the predicted category\n#         cv2.imwrite(os.path.join(new_dir, f'{category}_{frame_count}.png'), frame_gray)\n\n#         frame_count += 1\n\n#     cap.release()\n#     cv2.destroyAllWindows()\n\n# # Test the function\n# video_path = \"/kaggle/input/test-video/WhatsApp Video 2024-02-12 at 21.58.53_abdb8c47.mp4\"  # Replace with your video path\n# extract_and_predict(video_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.420177Z","iopub.status.idle":"2024-02-26T03:57:40.420541Z","shell.execute_reply.started":"2024-02-26T03:57:40.420360Z","shell.execute_reply":"2024-02-26T03:57:40.420377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST WITH GIF\n","metadata":{}},{"cell_type":"code","source":"# import cv2\n# import numpy as np\n# import os\n# from keras.models import load_model\n# from PIL import Image\n\n# categories_labels = {'Fighting': 0, 'Shoplifting': 1, 'Abuse': 2, 'Arrest': 3, 'Shooting': 4, 'Robbery': 5, 'Explosion': 6}\n# labels_categories = {v: k for k, v in categories_labels.items()}  # reverse dictionary for label lookup\n\n# # Load the trained model\n# model = load_model('/kaggle/input/cnn_lstm/keras/cnn_lstm/1/CNN_LSTM.h5')\n\n# def predict_image(image):\n#     # Resize the image\n#     image = cv2.resize(image, (50, 50))\n\n#     # Reshape the image to 4D array for CNN and LSTM input\n#     image_cnn = image.reshape((1,) + image.shape + (1,))\n#     image_lstm = image.reshape((1,) + (-1, 1))\n\n#     # Use the model to predict the category of the image\n#     prediction = model.predict([image_cnn, image_lstm])\n\n#     # Find the category with the highest probability\n#     label = np.argmax(prediction)\n\n#     # Return the name of the category\n#     return labels_categories[label]\n\n# def extract_and_predict(gif_path):\n#     # Open the gif image\n#     gif = Image.open(gif_path)\n\n#     # Extract all frames from the gif\n#     frames = []\n#     try:\n#         while True:\n#             gif.seek(gif.tell() + 1)\n#             frames.append(np.array(gif.convert('L')))  # Convert image to grayscale\n#     except EOFError:\n#         pass  # end of sequence\n\n#     # Predict the category of each frame and save it in a new directory\n#     new_dir = 'predicted_images'\n#     os.makedirs(new_dir, exist_ok=True)\n#     last_category = None  # variable to keep track of the last predicted category\n#     for i, frame in enumerate(frames):\n#         category = predict_image(frame)\n#         if category != last_category:  # only print the category if it's different from the last one\n#             print('Frame', i, 'Category:', category)\n#         last_category = category  # update the last predicted category\n#         cv2.imwrite(os.path.join(new_dir, f'{category}_{i}.png'), frame)\n\n# # Test the function\n# gif_path = \"/kaggle/input/test-gif/WhatsApp Video 2024-02-12 at 21.51.27_95c67b1a.gif\"  # Replace with your gif path\n# extract_and_predict(gif_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.421533Z","iopub.status.idle":"2024-02-26T03:57:40.421915Z","shell.execute_reply.started":"2024-02-26T03:57:40.421724Z","shell.execute_reply":"2024-02-26T03:57:40.421741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sending mail through SMTP Server ","metadata":{}},{"cell_type":"code","source":"# import smtplib\n# from email.message import EmailMessage\n\n# email = EmailMessage()\n# email['from']='Subash'\n# email['to']='subashs10011@gmail.com'\n# email['subject']='You won 1,000,000 dollars !'\n\n# email.set_content('I am a python master !')\n\n# with smtplib.SMPTP(host='smtp.gmail.com', port=587) as smtp:\n#     smtp.ehlo()\n#     smtp.starttls()\n#     smtp.login('dummyemail@gmail.com','abc123')\n#     smtp.send_message(email)\n#     print(\"email sent\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.423217Z","iopub.status.idle":"2024-02-26T03:57:40.423583Z","shell.execute_reply.started":"2024-02-26T03:57:40.423400Z","shell.execute_reply":"2024-02-26T03:57:40.423417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom email.mime.image import MIMEImage\n\nHOST = \"smtp.outlook.com\"\nPORT = 587\n\nFROM_EMAIL = \"subashs12344@outlook.com\"\nTO_EMAIL = \"subashs10011@gmail.com\"\nPASSWORD = \"Project@12\"\n\nmessage = MIMEMultipart()\nmessage['From'] = FROM_EMAIL\nmessage['To'] = TO_EMAIL\nmessage['Subject'] = \"Hello, this is Subash\"\n\n# Add message body\nbody = \"This is the message body.\"\nmessage.attach(MIMEText(body, 'plain'))\n\n# Attach image\nimage_url = \"/kaggle/input/fight/fighting-1200x801.jpg\"  # Update the image URL with the correct path\nwith open(image_url, 'rb') as attachment:\n    image_part = MIMEImage(attachment.read(), name=\"fighting-1200x801.jpg\")\n\nimage_part.add_header('Content-Disposition', 'attachment', filename=\"fighting-1200x801.jpg\")\nmessage.attach(image_part)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.425167Z","iopub.status.idle":"2024-02-26T03:57:40.425722Z","shell.execute_reply.started":"2024-02-26T03:57:40.425437Z","shell.execute_reply":"2024-02-26T03:57:40.425463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import smtplib\nimport getpass\n\nHOST = 'smtp-mail.outlook.com'\nPORT = 587\n\nFROM_EMAIL = \"subash12344@outlook.com\"\nTO_EMAIL = \"subashscr7@gmail.com\"\nPASSWORD = \"Project@12\"\n\nMESSAGE = \"\"\"Subject: hello this is subash\"\"\"\n\nsmtp = smtplib.SMTP(HOST, PORT)\n\nstatus_code, response = smtp.ehlo()\nprint(f\"[*] Echoing the server: {status_code} {response}\")\n\nstatus_code, response = smtp.starttls()\nprint(f\"[*] Starting TLS connection: {status_code} {response}\")\n\nstatus_code, response = smtp.login(FROM_EMAIL, PASSWORD)\nprint(f\"[*] Logging in: {status_code} {response}\")\n\nsmtp.sendmail(FROM_EMAIL, TO_EMAIL, MESSAGE)\nsmtp.quit()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.426964Z","iopub.status.idle":"2024-02-26T03:57:40.427531Z","shell.execute_reply.started":"2024-02-26T03:57:40.427252Z","shell.execute_reply":"2024-02-26T03:57:40.427279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import smtplib\nimport getpass\n\nHOST = \"smtp-mail.outlook.com\"\nPORT = 587\n\nFROM_EMAIL = \"subash12344@outlook.com\"\nTO_EMAIL = \"subashscr7@gmail.com\"\nPASSWORD = \"Project@12\"\n\nMESSAGE = \"\"\"Subject: hello this is subash\"\"\"\n\nsmtp = smtplib.SMTP(HOST, PORT)\n\nstatus_code, response = smtp.ehlo()\nprint(f\"[*] Echoing the server: {status_code} {response}\")\n\nstatus_code, response = smtp.starttls()\nprint(f\"[*] Starting TLS connection: {status_code} {response}\")\n\nstatus_code, response = smtp.login(FROM_EMAIL, PASSWORD)\nprint(f\"[*] Logging in: {status_code} {response}\")\n\nsmtp.sendmail(FROM_EMAIL, TO_EMAIL, MESSAGE)\nsmtp.quit()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.428977Z","iopub.status.idle":"2024-02-26T03:57:40.429537Z","shell.execute_reply.started":"2024-02-26T03:57:40.429262Z","shell.execute_reply":"2024-02-26T03:57:40.429288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TEST EMAIL KSK","metadata":{}},{"cell_type":"code","source":"import smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\nHOST = 'smtp-mail.outlook.com'\nPORT = 587\nUSERNAME = 'subash12344@outlook.com'\nPASSWORD = 'Project@12'\n\n# Create a MIME multipart message\nmessage = MIMEMultipart()\nmessage['From'] = USERNAME\nmessage['To'] = 'sureshvel2002@gmail.com'\nmessage['Subject'] = 'Test Email'\n\n# Add message body\nmessage.attach(MIMEText('This is a test email.', 'plain'))\n\n# Connect to the SMTP server\ntry:\n    smtp = smtplib.SMTP(HOST, PORT)\n    smtp.starttls()\n    smtp.login(USERNAME, PASSWORD)\n\n    # Send the email\n    smtp.sendmail(USERNAME,'sureshvel2002@gmail.com', message.as_string())\n    print('Email sent successfully!')\n\nexcept Exception as e:\n    print('Error sending email:', e)\n\nfinally:\n    if 'smtp' in locals():\n        smtp.quit()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.431027Z","iopub.status.idle":"2024-02-26T03:57:40.432564Z","shell.execute_reply.started":"2024-02-26T03:57:40.432251Z","shell.execute_reply":"2024-02-26T03:57:40.432280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom email.mime.image import MIMEImage\n\ndef send_message_with_image(message, image_path):\n    smtp_server = 'smtp-mail.outlook.com'  # Update with your SMTP server\n    smtp_port = 587  # Update with your SMTP port number\n\n    # Connect to the SMTP server\n    s = smtplib.SMTP(smtp_server, smtp_port)\n    s.starttls()  # Enable TLS encryption\n    # If your SMTP server requires authentication, uncomment the following lines and provide your credentials\n    s.login('subash12344@outlook.com','Project@12')\n\n    # Attach image to the message\n    with open(image_path, 'rb') as fp:\n        img_data = fp.read()\n    image = MIMEImage(img_data, name=os.path.basename(image_path))\n    message.attach(image)\n\n    # Send the email\n    s.sendmail(message['From'], message['To'], message.as_string())\n\n    # Close the connection\n    s.quit()\n\ndef create_message(sender, recipient, subject, body):\n    # Create the email message\n    message = MIMEMultipart()\n    message['From'] = sender\n    message['To'] = recipient\n    message['Subject'] = subject\n\n    # Attach the body of the email\n    message.attach(MIMEText(body, 'plain'))\n\n    return message\n\nif __name__ == '__main__':\n    # Provide the necessary details\n    sender_email = 'subash12344@outlook.com'\n    recipient_email = 'sureshvel2002@gmail.com'\n    subject = 'Message with Image'\n    body = 'This email contains an image attachment.'\n\n    # Create the message\n    message = create_message(sender_email, recipient_email, subject, body)\n\n    # Provide the path to the image file\n    image_path = '/kaggle/input/fight/fighting-1200x801.jpg'  # Update with the correct image path\n\n    # Send the message with the image attachment\n    send_message_with_image(message, image_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T03:57:40.434366Z","iopub.status.idle":"2024-02-26T03:57:40.434911Z","shell.execute_reply.started":"2024-02-26T03:57:40.434626Z","shell.execute_reply":"2024-02-26T03:57:40.434651Z"},"trusted":true},"execution_count":null,"outputs":[]}]}